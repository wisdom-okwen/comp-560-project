{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fvIg17w0I53"
   },
   "source": [
    "## *Spring 2025*\n",
    "Paul Signorelli, Christopher Sáez, Wisdom Okwen, Austin Campbell, Ethan Byrd, Will Scuria\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkidxAbTUApE"
   },
   "source": [
    "# 1.Business Problem: Customer Churn\n",
    "\n",
    "\n",
    "- The dataset is based on real bank data from 2022, but was slightly modified to:\n",
    "    - preserve real customers privacies  \n",
    "    - preserve the bank's privacy  \n",
    "    - allow for richer analysis  \n",
    "- To prevent customers from churning (i.e., take steps to incentivice them to stay), we need to be able to faithfully identify them.\n",
    "\n",
    ">Task: Predict which customers are most likely to churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-EASLZJUAz7"
   },
   "source": [
    "# 2. Load, Wrangle, and Clean Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AUQw_sQ2-CuA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1743556417762,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "Ieo2H43Q9saV",
    "outputId": "6b2bcca0-423c-44eb-c2ef-04149332251f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClientID</th>\n",
       "      <th>Surname</th>\n",
       "      <th>Firstname</th>\n",
       "      <th>FICOScore</th>\n",
       "      <th>Subsidiary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Products</th>\n",
       "      <th>BankCC</th>\n",
       "      <th>Active</th>\n",
       "      <th>RegDeposits</th>\n",
       "      <th>LifeInsur</th>\n",
       "      <th>PlatStatus</th>\n",
       "      <th>Terminated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61BOS20150MF65876258487565N</td>\n",
       "      <td>Myles</td>\n",
       "      <td>Fidel</td>\n",
       "      <td>657</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>64821.12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91CHL20170DA95890902611393N</td>\n",
       "      <td>Drenner</td>\n",
       "      <td>Arron</td>\n",
       "      <td>493</td>\n",
       "      <td>Chapel Hill</td>\n",
       "      <td>Male</td>\n",
       "      <td>64</td>\n",
       "      <td>90161.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5599</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91CHL20180MC38607441559869N</td>\n",
       "      <td>Muir</td>\n",
       "      <td>Charolette</td>\n",
       "      <td>820</td>\n",
       "      <td>Chapel Hill</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61BOS20110SH53586596382094N</td>\n",
       "      <td>Schimpf</td>\n",
       "      <td>Herschel</td>\n",
       "      <td>670</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Male</td>\n",
       "      <td>37</td>\n",
       "      <td>230.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40ATL20110MK15149165663931P</td>\n",
       "      <td>Montez</td>\n",
       "      <td>Kisha</td>\n",
       "      <td>664</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>76318.32</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5278</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>40ATL20160TJ2301576765838N</td>\n",
       "      <td>Tondreau</td>\n",
       "      <td>Jeffrey</td>\n",
       "      <td>678</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>88960.56</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>61BOS20150HB1119146617276N</td>\n",
       "      <td>Hevrin</td>\n",
       "      <td>Brad</td>\n",
       "      <td>627</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>862.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>40ATL20140RP44230979729440N</td>\n",
       "      <td>Russer</td>\n",
       "      <td>Penney</td>\n",
       "      <td>682</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>76374.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>40ATL20140PB19106060056904N</td>\n",
       "      <td>Polizio</td>\n",
       "      <td>Brigette</td>\n",
       "      <td>839</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>112642.93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>61BOS20100BS92391635490059N</td>\n",
       "      <td>Blessinger</td>\n",
       "      <td>Sade</td>\n",
       "      <td>357</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>-353.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ClientID     Surname   Firstname  FICOScore  \\\n",
       "0      61BOS20150MF65876258487565N       Myles       Fidel        657   \n",
       "1      91CHL20170DA95890902611393N     Drenner       Arron        493   \n",
       "2      91CHL20180MC38607441559869N        Muir  Charolette        820   \n",
       "3      61BOS20110SH53586596382094N     Schimpf    Herschel        670   \n",
       "4      40ATL20110MK15149165663931P      Montez       Kisha        664   \n",
       "...                            ...         ...         ...        ...   \n",
       "23995   40ATL20160TJ2301576765838N    Tondreau     Jeffrey        678   \n",
       "23996   61BOS20150HB1119146617276N      Hevrin        Brad        627   \n",
       "23997  40ATL20140RP44230979729440N      Russer      Penney        682   \n",
       "23998  40ATL20140PB19106060056904N     Polizio    Brigette        839   \n",
       "23999  61BOS20100BS92391635490059N  Blessinger        Sade        357   \n",
       "\n",
       "        Subsidiary  Gender  Age    Balance  Products  BankCC  Active  \\\n",
       "0           Boston    Male   28   64821.12         2       0       0   \n",
       "1      Chapel Hill    Male   64   90161.70         1       0       1   \n",
       "2      Chapel Hill  Female   46       0.00         1       0       0   \n",
       "3           Boston    Male   37     230.10         2       1       1   \n",
       "4          Atlanta  Female   33   76318.32         2       1       1   \n",
       "...            ...     ...  ...        ...       ...     ...     ...   \n",
       "23995      Atlanta    Male   47   88960.56         2       1       0   \n",
       "23996       Boston    Male   28     862.68         1       0       1   \n",
       "23997      Atlanta  Female   48   76374.48         2       0       0   \n",
       "23998      Atlanta  Female   39  112642.93         1       1       1   \n",
       "23999       Boston  Female   34    -353.34         1       0       0   \n",
       "\n",
       "       RegDeposits  LifeInsur PlatStatus  Terminated  \n",
       "0            15330          0          0           0  \n",
       "1             5599          0          0           0  \n",
       "2            15185          0          0           1  \n",
       "3               13          1          0           0  \n",
       "4             5278          1          1           0  \n",
       "...            ...        ...        ...         ...  \n",
       "23995        14963          0          0           1  \n",
       "23996        15206          0          0           0  \n",
       "23997          189          1          0           0  \n",
       "23998         6696          0          0           1  \n",
       "23999        11367          0          0           0  \n",
       "\n",
       "[24000 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data.json as a dataframe\n",
    "df = pd.read_json('data/data.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG: If the cell above does not work, try uncommenting the bottom line of this cell and running it first\n",
    "\n",
    "# Download training data as \"data.json\"\n",
    "# !wget -O data.json \"https://raw.githubusercontent.com/wisdom-okwen/comp-560-project/refs/heads/main/data/Bank_Churn.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1743556417882,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "co98E2uL90vc",
    "outputId": "57cf52bb-fa18-4660-b1b2-b5a0178fb42c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Ranges: {'FICOScore': (350, 850), 'Age': (18, 71), 'Balance': (-128372.66, 260951.61), 'Products': (1, 3), 'RegDeposits': (0, 18833)}\n"
     ]
    }
   ],
   "source": [
    "### Cleaning the Data\n",
    "\n",
    "# Categorical Columns\n",
    "categorical_columns = ['Gender', 'Subsidiary', 'BankCC', 'Active', 'LifeInsur', 'PlatStatus', 'Terminated']\n",
    "\n",
    "# Fixing Categorical Columns\n",
    "# Fixing typo in 'Gender'\n",
    "df['Gender'] = df['Gender'].replace('Feale', 'Female')\n",
    "\n",
    "# Fixing 'BankCC' - assuming binary variable (replace 2 with 1)\n",
    "df['BankCC'] = df['BankCC'].replace(2, 1)\n",
    "\n",
    "# Fixing 'Active' - assuming binary variable (replace 2 with 1)\n",
    "df['Active'] = df['Active'].replace(2, 1)\n",
    "\n",
    "# Fixing 'PlatStatus' - replacing 'yes' with '1'\n",
    "df['PlatStatus'] = df['PlatStatus'].replace('yes', '1')\n",
    "\n",
    "# Converting categorical columns to type 'category'\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# Numerical Variables\n",
    "valid_ranges = {\n",
    "    'FICOScore': (300, 850),\n",
    "    'Age': (18, 100),\n",
    "    'Balance': (-np.inf, np.inf),  # Allowing negative balances\n",
    "    'Products': (1, 5),\n",
    "    'RegDeposits': (0, 100000)\n",
    "}\n",
    "\n",
    "def fix_numerical_variable(data, column, valid_range):\n",
    "    lower, upper = valid_range\n",
    "    # Replace invalid or missing values with the median of valid values\n",
    "    median = data[column][(data[column] >= lower) & (data[column] <= upper)].median()\n",
    "    # Cast the median to the same type as the column\n",
    "    if pd.api.types.is_integer_dtype(data[column]):\n",
    "        median = int(median)\n",
    "    elif pd.api.types.is_float_dtype(data[column]):\n",
    "        median = float(median)\n",
    "\n",
    "    # Replace invalid or missing values\n",
    "    data.loc[(data[column] < lower) | (data[column] > upper) | (data[column].isnull()), column] = median\n",
    "\n",
    "    # Calculate bounds for outlier removal\n",
    "    mean = data[column].mean()\n",
    "    std_dev = data[column].std()\n",
    "    upper_limit = mean + 3 * std_dev\n",
    "    lower_limit = mean - 3 * std_dev\n",
    "\n",
    "    # Remove outliers\n",
    "    return data[(data[column] >= lower_limit) & (data[column] <= upper_limit)]\n",
    "\n",
    "# Cleaning numerical variables\n",
    "for col, range_ in valid_ranges.items():\n",
    "    df = fix_numerical_variable(df, col, range_)\n",
    "\n",
    "# After Cleaning: Verify Ranges\n",
    "cleaned_ranges = {col: (df[col].min(), df[col].max()) for col in valid_ranges.keys()}\n",
    "\n",
    "print(\"Cleaned Ranges:\", cleaned_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9tm1SZyIFeQ"
   },
   "source": [
    "# 3. Build a Predictive Model: Supervised Learning\n",
    "- It's time to train a machine learning model to predict which customers are likely to churn.\n",
    "  - We have variables (columns) describing customers: our independent variables or Xs.\n",
    "  - We have an outcome (\"terminated\") for each custiomer: our dependent variabel or Y.\n",
    "  \n",
    "Let's create a classification model that can predict whether a customer will churn or not using the *Bank_Churn_Train.json* dataset. These are the steps to train the machine learning model:\n",
    "\n",
    "1. Separate the independent (X) variables from the dependent (Y) variable.\n",
    "2. Transform categorical independept variables (X) into binary variables (i.e., dummy coding or one-hot encoding.)\n",
    "3. Split the dataset into a *train* and *test* set:\n",
    "   - Train the model on the *train* set, and then evaluate its performance on the *test* set (which it has not seen during training) to assess its accuracy.\n",
    "4. Load and instantiate (i.e., set up) a classification model. This includes selecting the model type and configuring parameters that control how it is trained.\n",
    "5. Train the model (run the training process).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5uIfqqDJMmo"
   },
   "source": [
    "### 3.1 Separate the independent (X) variables from the dependent (Y) variable\n",
    "- Let's separate the independent (X) variables from the dependent (Y) variable (Terminated) in the dataframe. Keep only variables that are either categorical, boolean, or numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1743556417885,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "ycsw6-G4NHss",
    "outputId": "3b6780b4-77a3-4fe3-b286-f45282ad1fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent variables (X):\n",
      "   FICOScore   Subsidiary  Gender  Age   Balance  Products BankCC Active  \\\n",
      "0        657       Boston    Male   28  64821.12         2      0      0   \n",
      "1        493  Chapel Hill    Male   64  90161.70         1      0      1   \n",
      "2        820  Chapel Hill  Female   46      0.00         1      0      0   \n",
      "3        670       Boston    Male   37    230.10         2      1      1   \n",
      "4        664      Atlanta  Female   33  76318.32         2      1      1   \n",
      "\n",
      "   RegDeposits LifeInsur PlatStatus  \n",
      "0        15330         0          0  \n",
      "1         5599         0          0  \n",
      "2        15185         0          0  \n",
      "3           13         1          0  \n",
      "4         5278         1          1  \n",
      "(23467, 11)\n",
      "(23467,)\n",
      "\n",
      "Dependent variable (Y):\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: Terminated, dtype: category\n",
      "Categories (2, int64): [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Separate the independent (X) variables from the dependent (Y) variable (Terminated) in my dataframe. Keep only variables that are either categorical, boolean, or numeric.\n",
    "\n",
    "# Assuming 'df' is your DataFrame as defined in the provided code.\n",
    "\n",
    "# Separate independent (X) and dependent (Y) variables\n",
    "X = df.drop('Terminated', axis=1)\n",
    "y = df['Terminated']\n",
    "\n",
    "# Keep only specified data types in X\n",
    "X = X.select_dtypes(include=['category', 'bool', 'number'])\n",
    "\n",
    "print(\"Independent variables (X):\")\n",
    "print(X.head())\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(\"\\nDependent variable (Y):\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkJpgXPC_Oih"
   },
   "source": [
    "### 3.2 Transform categorical independept variables (X) into binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1743556417912,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "jYVX1dLoNIOZ",
    "outputId": "e3d161f1-9c79-4c62-a42f-03842c18647c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Independent variables (X) after one-hot encoding:\n",
      "   FICOScore  Age   Balance  Products  RegDeposits  Subsidiary_Boston  \\\n",
      "0        657   28  64821.12         2        15330               True   \n",
      "1        493   64  90161.70         1         5599              False   \n",
      "2        820   46      0.00         1        15185              False   \n",
      "3        670   37    230.10         2           13               True   \n",
      "4        664   33  76318.32         2         5278              False   \n",
      "\n",
      "   Subsidiary_Chapel Hill  Gender_Male  BankCC_1  Active_1  LifeInsur_1  \\\n",
      "0                   False         True     False     False        False   \n",
      "1                    True         True     False      True        False   \n",
      "2                    True        False     False     False        False   \n",
      "3                   False         True      True      True         True   \n",
      "4                   False        False      True      True         True   \n",
      "\n",
      "   PlatStatus_1  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4          True  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23467, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform one-hot encoding on categorical features\n",
    "X = pd.get_dummies(X, columns=X.select_dtypes(include=['category']).columns, drop_first=True)\n",
    "\n",
    "print(\"\\nIndependent variables (X) after one-hot encoding:\")\n",
    "print(X.head())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcsV3e4o9hNK"
   },
   "source": [
    "### 3.3 Split the dataset into a training set and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1743556417948,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "U22OVFwKlrj6",
    "outputId": "b6e2d8a6-8758-4e88-9ba1-c5718293875f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (18773, 12)\n",
      "X_test shape: (4694, 12)\n",
      "y_train shape: (18773,)\n",
      "y_test shape: (4694,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% test\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCmIgj4Z9zF5"
   },
   "source": [
    "### 3.4 Instantiate the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7118,
     "status": "ok",
     "timestamp": 1743556425065,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "hsPq2Dt5mM48",
    "outputId": "8a064e2f-2de4-46ed-b5ca-13b1e603c030"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Train, make predictions, and evaluate the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Random Forest Classifier: 0.9054111631870473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      3562\n",
      "           1       0.85      0.74      0.79      1132\n",
      "\n",
      "    accuracy                           0.91      4694\n",
      "   macro avg       0.88      0.85      0.87      4694\n",
      "weighted avg       0.90      0.91      0.90      4694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Random Forest Classifier: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7EE5yNzw9Hf"
   },
   "source": [
    "# 4. Evaluate Performance and Improve the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89QsCp2WCNJG"
   },
   "source": [
    "### 4.1 Generalization\n",
    "\n",
    "Ideally, a model performs equally well on data it has not seen. In other words, it ***generalizes*** well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20979,
     "status": "ok",
     "timestamp": 1743556446053,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "547q4MHsrMcU",
    "outputId": "7104b9cd-ad63-4b9d-fd1c-ea974d978e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.90093737 0.90796762 0.90176859 0.89963776 0.89814618]\n",
      "Mean cross-validation score: 0.901691502024927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Example using 5-fold cross-validation\n",
    "cv_scores = cross_val_score(rf_classifier, X, y, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDmzpzyJNFK3"
   },
   "source": [
    "# 5. Tensor deep learning model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Prepare the data and preprocess the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1743556446240,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "GveQB2nWZgm5",
    "outputId": "f75027d9-9939-4296-fdaa-bcdef20cdbf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepared Data:\n",
      "   FICOScore       Age   Balance  Products  RegDeposits  YearOpened    Tenure  \\\n",
      "0   0.306362 -1.042322 -0.012109  0.675159     0.127654    0.397984 -0.397984   \n",
      "1  -1.250425  2.303642  0.027026 -0.761477    -0.093466    1.020321 -1.020321   \n",
      "2   1.853656  0.630660 -0.112217 -0.761477     0.124360    1.331490 -1.331490   \n",
      "3   0.429766 -0.205831 -0.111862  0.675159    -0.220398   -0.846689  0.846689   \n",
      "4   0.372810 -0.577605  0.005646  0.675159    -0.100760   -0.846689  0.846689   \n",
      "\n",
      "   Subsidiary_Boston  Subsidiary_Chapel Hill  Gender_Female  Gender_Male  \\\n",
      "0           1.007276               -0.572603      -0.935571     0.935649   \n",
      "1          -0.992776                1.746410      -0.935571     0.935649   \n",
      "2          -0.992776                1.746410       1.068866    -1.068777   \n",
      "3           1.007276               -0.572603      -0.935571     0.935649   \n",
      "4          -0.992776               -0.572603       1.068866    -1.068777   \n",
      "\n",
      "   BankCC_1  BankCC_2  Active_1  Active_2  LifeInsur_1  PlatStatus_1  \\\n",
      "0 -1.325413 -0.006455 -0.915783 -0.006455    -0.623996     -0.489757   \n",
      "1 -1.325413 -0.006455  1.091962 -0.006455    -0.623996     -0.489757   \n",
      "2 -1.325413 -0.006455 -0.915783 -0.006455    -0.623996     -0.489757   \n",
      "3  0.754482 -0.006455  1.091962 -0.006455     1.602574     -0.489757   \n",
      "4  0.754482 -0.006455  1.091962 -0.006455     1.602574      2.041830   \n",
      "\n",
      "   PlatStatus_yes  Terminated_1  \n",
      "0       -0.006455     -0.567021  \n",
      "1       -0.006455     -0.567021  \n",
      "2       -0.006455      1.763602  \n",
      "3       -0.006455     -0.567021  \n",
      "4       -0.006455     -0.567021  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.read_json('data/data.json')\n",
    "\n",
    "# 1. Feature Engineering: Extract \"YearOpened\" from ClientID and compute \"Tenure\"\n",
    "# Assuming characters at positions 6 to 9 in ClientID represent the account opening year (e.g., \"2015\")\n",
    "df['YearOpened'] = df['ClientID'].str[5:9].astype(int)\n",
    "current_year = 2022  # Alternatively, you could use: pd.Timestamp.now().year\n",
    "df['Tenure'] = current_year - df['YearOpened']\n",
    "\n",
    "# 2. Drop columns that are not useful for prediction (e.g., ClientID, Surname, Firstname)\n",
    "df.drop(['ClientID', 'Surname', 'Firstname'], axis=1, inplace=True)\n",
    "\n",
    "# 3. Convert appropriate columns to categorical type\n",
    "# Add \"PlatStatus\" to the list of categorical columns\n",
    "categorical_columns = ['Subsidiary', 'Gender', 'BankCC', 'Active', 'LifeInsur', 'PlatStatus', 'Terminated']\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# 4. One-Hot Encode the categorical features\n",
    "df_prepared = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# 5. Optional: Scale numerical features\n",
    "# Identify numerical columns (excluding the target 'Terminated')\n",
    "# Ensure that categorical features are also excluded here\n",
    "num_cols = df_prepared.columns.difference(['Terminated'] + categorical_columns)  # Exclude categorical columns\n",
    "scaler = StandardScaler()\n",
    "df_prepared[num_cols] = scaler.fit_transform(df_prepared[num_cols])\n",
    "\n",
    "print(\"\\nPrepared Data:\")\n",
    "print(df_prepared.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create tensors and split data into training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54890,
     "status": "ok",
     "timestamp": 1743556501204,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "4sKcaAgRYnx2",
    "outputId": "3d438896-ccf3-4520-d59f-3231d17564f2"
   },
   "outputs": [],
   "source": [
    "X_new = df_prepared.drop('Terminated_1', axis=1)\n",
    "y_new = df_prepared['Terminated_1']\n",
    "# Convert pandas DataFrames/Series to PyTorch tensors\n",
    "# The 'ClientID' column has already been dropped during preprocessing.\n",
    "# Ensure X has the correct dimensions for the neural network.\n",
    "X_tensor = torch.tensor(X_new.astype(float).values, dtype=torch.float32)\n",
    "\n",
    "# If y is binary (0/1), we can use Long type for classification with CrossEntropyLoss.\n",
    "y_tensor = torch.tensor(y_new.values, dtype=torch.long)\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader for batching during training\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Create the deep learning model with loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning neural network Model\n",
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ChurnModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "          nn.Linear(input_dim, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.3), # Dropout is a form of regularization\n",
    "          nn.Linear(64, 32),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.3),\n",
    "          nn.Linear(32, 2)\n",
    "       )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Get input dimension from X_tensor\n",
    "input_dim = X_tensor.shape[1]\n",
    "model = ChurnModel(input_dim)\n",
    "\n",
    "# Set Loss Function and Optimizer \n",
    "criterion = nn.CrossEntropyLoss()  # suitable for multi-class (even if binary)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Train the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.3033\n",
      "Epoch [2/50], Loss: 0.2552\n",
      "Epoch [3/50], Loss: 0.2431\n",
      "Epoch [4/50], Loss: 0.2420\n",
      "Epoch [5/50], Loss: 0.2373\n",
      "Epoch [6/50], Loss: 0.2316\n",
      "Epoch [7/50], Loss: 0.2300\n",
      "Epoch [8/50], Loss: 0.2338\n",
      "Epoch [9/50], Loss: 0.2248\n",
      "Epoch [10/50], Loss: 0.2239\n",
      "Epoch [11/50], Loss: 0.2241\n",
      "Epoch [12/50], Loss: 0.2212\n",
      "Epoch [13/50], Loss: 0.2206\n",
      "Epoch [14/50], Loss: 0.2171\n",
      "Epoch [15/50], Loss: 0.2190\n",
      "Epoch [16/50], Loss: 0.2165\n",
      "Epoch [17/50], Loss: 0.2136\n",
      "Epoch [18/50], Loss: 0.2116\n",
      "Epoch [19/50], Loss: 0.2160\n",
      "Epoch [20/50], Loss: 0.2140\n",
      "Epoch [21/50], Loss: 0.2167\n",
      "Epoch [22/50], Loss: 0.2117\n",
      "Epoch [23/50], Loss: 0.2091\n",
      "Epoch [24/50], Loss: 0.2111\n",
      "Epoch [25/50], Loss: 0.2089\n",
      "Epoch [26/50], Loss: 0.2081\n",
      "Epoch [27/50], Loss: 0.2104\n",
      "Epoch [28/50], Loss: 0.2097\n",
      "Epoch [29/50], Loss: 0.2105\n",
      "Epoch [30/50], Loss: 0.2049\n",
      "Epoch [31/50], Loss: 0.2076\n",
      "Epoch [32/50], Loss: 0.2061\n",
      "Epoch [33/50], Loss: 0.2071\n",
      "Epoch [34/50], Loss: 0.2047\n",
      "Epoch [35/50], Loss: 0.2072\n",
      "Epoch [36/50], Loss: 0.2063\n",
      "Epoch [37/50], Loss: 0.2045\n",
      "Epoch [38/50], Loss: 0.2038\n",
      "Epoch [39/50], Loss: 0.2055\n",
      "Epoch [40/50], Loss: 0.2026\n",
      "Epoch [41/50], Loss: 0.2047\n",
      "Epoch [42/50], Loss: 0.2004\n",
      "Epoch [43/50], Loss: 0.2053\n",
      "Epoch [44/50], Loss: 0.2025\n",
      "Epoch [45/50], Loss: 0.2025\n",
      "Epoch [46/50], Loss: 0.2047\n",
      "Epoch [47/50], Loss: 0.2005\n",
      "Epoch [48/50], Loss: 0.2007\n",
      "Epoch [49/50], Loss: 0.2002\n",
      "Epoch [50/50], Loss: 0.1998\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Evaluate the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1743556501224,
     "user": {
      "displayName": "Wiz Ok",
      "userId": "05388041491690398710"
     },
     "user_tz": 240
    },
    "id": "xe7waFOUbISz",
    "outputId": "bf0bcef7-5ce8-451f-ae63-2c9323dad1ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9114583134651184\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    # Get predicted classes by taking the argmax along the class dimension\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    test_accuracy = (predicted == y_test).float().mean()\n",
    "    print(\"Test Accuracy:\", test_accuracy.item())\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Virtual_Environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
